{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models output text. But there are times where you want to get more structured information than just text back\n",
    "\n",
    "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "- **Get format instructions**: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- **Parse**: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output Parsing\n",
    "    - StrOutputParser\n",
    "    - JsonOutputParser\n",
    "    - CSV Output Parser\n",
    "    - Datatime Output Parser\n",
    "    - Structured Output Parser (Pydanitc or Json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pydantinc` Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')\n",
    "\n",
    "# langfuse or opik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        PromptTemplate\n",
    "                                        )\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:3b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import  Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user\"\"\"\n",
    "\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline of the joke\")\n",
    "    rating: Optional[int] = Field(description=\"The rating of the joke is from 1 to 10\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\": \"Why did the cat join a band?\", \"punchline\": \"Because it wanted to be the purr-cussionist!\", \"rating\": 8}\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog go to the vet?' punchline='Because he was feeling ruff!' rating=8\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': 'Tell me a joke about the dogs'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing with `.with_structured_output()` method\n",
    "- This method takes a schema as input which specifies the names, types, and descriptions of the desired output attributes.\n",
    "-  The schema can be specified as a TypedDict class, JSON Schema or a Pydantic class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the cat join a band?\n",
      "\n",
      "Because it wanted to be the purr-cussionist.\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke('Tell me a joke about the cat')\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Because it wanted to be a purr-cussionist!' punchline='Why did the cat join a band?' rating=8\n"
     ]
    }
   ],
   "source": [
    "output = structured_llm.invoke('Tell me a joke about the cat')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `JSON` Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output parsers accept a string or BaseMessage as input and can return an arbitrary type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"The setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"The punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"The rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\": \"Why did the cat join a band?\", \"punchline\": \"Because it wanted to be the purr-cussionist!\", \"rating\": null}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a joke. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'Why did the cat join a band?', 'punchline': 'Because it wanted to be the purr-cussionist!', 'rating': 8}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': 'Tell me a joke about the cat'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This output parser can be used when you want to return a list of comma-separated items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# value1, values2, values3, so on\n",
    "\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instruction = parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a list of values. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural language processing', 'large language models', 'machine learning algorithms', 'artificial intelligence', 'deep learning', 'text analysis', 'language understanding', 'semantic search', 'content optimization']\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': 'generate my website seo keywords. I have content about the NLP and LLM.'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatime Output Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gives output in datetime format. Sometimes throws error if the LLM output is not in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1447-02-24T19:58:26.676193Z, 0564-06-14T03:48:46.511169Z, 1476-11-17T13:44:27.402145Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "parser = DatetimeOutputParser()\n",
    "\n",
    "format_instruction = parser.get_format_instructions()\n",
    "print(format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "    Answer the user query with a datetime. Here is your formatting instruction.\n",
    "    {format_instruction}\n",
    "\n",
    "    Query: {query}\n",
    "    Answer:''',\n",
    "    input_variables=['query'],\n",
    "    partial_variables={'format_instruction': format_instruction}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1505-04-30 12:45:00\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'query': 'when the America got discovered?'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
